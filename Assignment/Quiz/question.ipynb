{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch, torchdata, torchtext\n",
    "from torch import nn\n",
    "import time\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 2422\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cpu'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the given dataset\n",
    "\n",
    "1. Create a variable to your dataset PATH *example:  ./data/*\n",
    "2. Load the csv files using pandas \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yelp = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "train_data_raw = pd.read_csv(\"train.csv\") \n",
    "test_data_raw = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 4)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets analyze the data a little\n",
    "\n",
    "#print and show how many unique classes are in the target\n",
    "\n",
    "classes = train_data_raw['target'].unique()\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_classes > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3263\n"
     ]
    }
   ],
   "source": [
    "##lets see how many columns are there\n",
    "#print the columns of the train_data_raw\n",
    "\n",
    "print(len(test_data_raw)) #write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lets remove the keywords and location columns. We only want to focus on the text and the predictions\n",
    "2. Lets split some training data to validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_PER = 2 #percentage of split for validation set 2 = 2%\n",
    "split =  int(len(train_data_raw) * (SPLIT_PER/100))\n",
    "\n",
    "dropped_train = train_data_raw.drop(columns=['id','keyword', 'location'], axis =1) \n",
    "#drop the id, keyowrd and location columns from the train_data_raw\n",
    "\n",
    "train_data = dropped_train[:-split]\n",
    "valid_data = dropped_train[-split:]\n",
    "\n",
    "assert train_data.shape == (len(train_data_raw) - split, 2)\n",
    "assert valid_data.shape == (split, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "After dropping columns and spliting!\n",
      "(7461, 2) (152, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_raw.shape)\n",
    "print(\"After dropping columns and spliting!\")\n",
    "print(train_data.shape, valid_data.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'are', 'learning', 'torchtext', 'in', 'AIT', '!']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "tokens = tokenizer(\"We are learning torchtext in AIT!\")  #some test\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all' 1]\n"
     ]
    }
   ],
   "source": [
    "for i in train_data.values:\n",
    "    print (i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the data_iter, \n",
    "# Mind that the data_iter in this case is pandas Dataframe\n",
    "#remove this line and code here\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter.values:\n",
    "        yield tokenizer(text) \n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "#set_default_index of the vocab to unknown tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(vocab) == 26442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bells': 17043,\n",
       " 'Escaping': 12472,\n",
       " 'charge': 2966,\n",
       " \"'m\": 59,\n",
       " 'putin': 24713,\n",
       " 'adoption': 6850,\n",
       " 'STILL': 6529,\n",
       " 'WOUNDS': 16371,\n",
       " 'Mafia': 6212,\n",
       " 'mass': 200,\n",
       " 'Lubbock': 6184,\n",
       " 'Gillibrand': 12913,\n",
       " 'Scarlet': 15416,\n",
       " 'depreciations': 17800,\n",
       " 'Bomb': 1013,\n",
       " '@WoundedPigeon': 9949,\n",
       " 'lvl': 23796,\n",
       " 'advice': 16695,\n",
       " '.': 6,\n",
       " 'restore': 3119,\n",
       " 'dominant': 17956,\n",
       " 'thunder': 475,\n",
       " '.@NorwayMFA': 8190,\n",
       " 'pitch': 3866,\n",
       " '@9NewsBrisbane': 8744,\n",
       " 'Odell': 14460,\n",
       " 'Quarantine': 761,\n",
       " 'point': 1142,\n",
       " '@ByTorrecilla': 8925,\n",
       " 'fruit': 3025,\n",
       " 'Some': 319,\n",
       " '&': 38,\n",
       " '@charstevens97': 10132,\n",
       " 'http://t.co/JlzK2HdeTG': 7409,\n",
       " 'Officer': 1265,\n",
       " 'LLF': 6136,\n",
       " 'WYOU': 16392,\n",
       " 'US': 245,\n",
       " '...': 18,\n",
       " '@SCynic1': 9707,\n",
       " 'WIN': 16358,\n",
       " 'appropriation': 6878,\n",
       " 'Join': 2411,\n",
       " '<bos>': 2,\n",
       " 'illegal': 2239,\n",
       " 'threat': 1818,\n",
       " 'Zhejiang': 16615,\n",
       " 'en\\x89Û': 7222,\n",
       " 'asswipe': 16889,\n",
       " 'Reactor': 2454,\n",
       " '<unk>': 0,\n",
       " 'suspect': 749,\n",
       " 'Andrea': 11042,\n",
       " 'Minority': 4427,\n",
       " 'illusion': 23303,\n",
       " 'http://t.co/0wbEcdMHQo': 18868,\n",
       " 'collapsed': 384,\n",
       " '3945': 8507,\n",
       " 'experiences': 18207,\n",
       " 'mail': 4980,\n",
       " 'Giant': 1886,\n",
       " 'http://t.co/2o7Eva1cOe': 19001,\n",
       " 'great': 324,\n",
       " '?': 5,\n",
       " 'GFZ': 12821,\n",
       " 'aviation': 6907,\n",
       " 'totally': 1241,\n",
       " 'Hearthstone': 13126,\n",
       " '<eos>': 3,\n",
       " 'daily': 1980,\n",
       " 'today': 160,\n",
       " 'die&gt': 17851,\n",
       " 'pm': 1064,\n",
       " 'Calgary': 534,\n",
       " 'Currensy': 12001,\n",
       " '@OneGreenPlanet': 9588,\n",
       " 'AND': 344,\n",
       " 'quality': 7740,\n",
       " 'notices': 2261,\n",
       " 'experts': 1990,\n",
       " '@Liana_Novoa': 9421,\n",
       " 'EFAK': 5841,\n",
       " 'DIES': 5769,\n",
       " '43rd': 4037,\n",
       " \"'\": 16,\n",
       " '<pad>': 1,\n",
       " 'Bombs': 1346,\n",
       " '@ijustine': 10354,\n",
       " 'jfc': 23510,\n",
       " 'crane': 7102,\n",
       " 'smoke': 355,\n",
       " '@WXII': 9929,\n",
       " 'aggressively': 16715,\n",
       " 'BWP': 5587,\n",
       " 'terrible': 3161,\n",
       " 'Obliterated': 2439,\n",
       " '#': 4,\n",
       " 'http://t.co/nmAUMYdKe1': 22050,\n",
       " 'was': 36,\n",
       " 'pdx911': 7676,\n",
       " 'Nice': 14348,\n",
       " '@chaosmagician97': 10129,\n",
       " 'the': 7,\n",
       " 'NE': 6280,\n",
       " 'sheriff': 25184,\n",
       " 'interesting!--Why': 23432,\n",
       " 'Smaug': 1598,\n",
       " '@YouTube': 142,\n",
       " 'http://t.co/9TyucdWh3': 19427,\n",
       " 'Ford': 4282,\n",
       " 'http://t.co/Qdf6ASaeLM': 20579,\n",
       " 'awesome': 1393,\n",
       " '@JulieChen': 9345,\n",
       " 'http://t.co/IzakNpJeQW': 20062,\n",
       " 'awake': 16933,\n",
       " 'crashes': 3671,\n",
       " 'Championship': 11769,\n",
       " 'non': 1520,\n",
       " 'face': 404,\n",
       " 'Financial': 1883,\n",
       " '@BasilDudin': 8867,\n",
       " 'Red': 727,\n",
       " 'http://t.co/imAWVMzs3A': 21727,\n",
       " 'much': 227,\n",
       " 'Unknowingly': 16201,\n",
       " '100': 954,\n",
       " 'ROIMentor': 14966,\n",
       " '@SirBrandonKnt': 9748,\n",
       " 'forget': 1774,\n",
       " 'http://t.co/3EV07PPaPn': 19023,\n",
       " 'but': 54,\n",
       " 'Russia': 1106,\n",
       " 'rescue': 525,\n",
       " 'ticketed': 25763,\n",
       " 'http://t.co/5uoOPhSqU3': 19187,\n",
       " '@tprimo24': 10750,\n",
       " 'Z10': 2934,\n",
       " 'Megadeth': 6236,\n",
       " 'unhappy': 25977,\n",
       " 'Trois': 16082,\n",
       " '18': 1157,\n",
       " 'Stole': 15700,\n",
       " 'Todd': 4611,\n",
       " 'yourself': 847,\n",
       " 'cheat': 7038,\n",
       " 'Team': 2897,\n",
       " 'that': 28,\n",
       " '@CowgirlLawyer': 8998,\n",
       " '@AndyGilder': 8811,\n",
       " 'rip': 24965,\n",
       " '!': 17,\n",
       " 'Supreme': 3520,\n",
       " 'Libyan': 13801,\n",
       " 'seems': 1805,\n",
       " 'http://t.co/ehomn68oJB': 21441,\n",
       " 'http://t.co/QWQnni7VMZ': 20569,\n",
       " 'DecisionsOnDecisions': 12144,\n",
       " 'her': 100,\n",
       " '6773': 5369,\n",
       " 'activity': 3590,\n",
       " 'myths': 24094,\n",
       " 'terms': 5215,\n",
       " 'group': 548,\n",
       " '@mmfa': 10502,\n",
       " 'lambasts': 23626,\n",
       " 'underway': 3980,\n",
       " 'Magic': 13999,\n",
       " 'a': 8,\n",
       " ':': 9,\n",
       " 'http://t.co/81nEizeknm': 19331,\n",
       " 'http://t.co/3hTJ2PypSg': 19058,\n",
       " '@_dmerida': 9992,\n",
       " 'Justin': 6102,\n",
       " 'North': 917,\n",
       " '@GraysonDolan': 9202,\n",
       " 'every': 272,\n",
       " 'NORTH': 6287,\n",
       " 'Katherine': 6111,\n",
       " ')': 46,\n",
       " 'mouse': 24052,\n",
       " 'Malaysian': 2427,\n",
       " 'COTE': 11648,\n",
       " 'Legionnaire': 13776,\n",
       " 'way': 169,\n",
       " '10': 533,\n",
       " 'Area': 1161,\n",
       " 'http://t.co/s4Srgrmqcz': 22332,\n",
       " 'wee': 8069,\n",
       " '@kadiegrr': 10394,\n",
       " 'costlier': 776,\n",
       " 'to': 10,\n",
       " 'Answers': 11055,\n",
       " 'Drago': 12269,\n",
       " 'Doing': 5817,\n",
       " 'Wow': 1610,\n",
       " '@LegacyOfTheSith': 9416,\n",
       " 'http://t.co/Lhw4vTbHZG': 20243,\n",
       " 'Center': 1085,\n",
       " 'Americans': 2683,\n",
       " 'SMITHSONIAN': 15283,\n",
       " 'or': 71,\n",
       " 'cunts': 4789,\n",
       " 'ARMY': 2674,\n",
       " 'Walerga': 6785,\n",
       " 'ember': 18089,\n",
       " 'Actions': 5510,\n",
       " 'Sandbox': 15388,\n",
       " 'erally': 18151,\n",
       " 'message': 1784,\n",
       " 'FAVOURITE': 12549,\n",
       " 'all': 65,\n",
       " 'La': 1575,\n",
       " 'http://t.co/wjNTaOkdHf': 22626,\n",
       " 'Dorman': 5821,\n",
       " '/': 60,\n",
       " 'probably': 946,\n",
       " 'mood': 2584,\n",
       " 'Mattingly': 14067,\n",
       " 'kicked': 3053,\n",
       " 'Legacy': 2420,\n",
       " 'bot': 6963,\n",
       " 'in': 11,\n",
       " 'seeing': 1323,\n",
       " '@JusReign': 9347,\n",
       " 'bike': 3616,\n",
       " 'http://t.co/rb02svlpPu': 22303,\n",
       " 'ISIL': 6057,\n",
       " '@RobertBEnglund': 9687,\n",
       " 'of': 12,\n",
       " 'STANDARD': 15321,\n",
       " 'http://t.co/kxSLfTZ2I5': 21870,\n",
       " 'PROPERTY': 2831,\n",
       " 'being': 181,\n",
       " 'Dramatic': 2729,\n",
       " 'Pub': 14869,\n",
       " 'overlooking': 7654,\n",
       " 'service': 1425,\n",
       " 'hunchback': 23249,\n",
       " '1880': 5327,\n",
       " 'Elvia': 12416,\n",
       " 'To': 108,\n",
       " 'Army': 250,\n",
       " '@Adanne': 8782,\n",
       " 'Milne': 14134,\n",
       " 'Carcinoma': 11721,\n",
       " 'misguided': 23976,\n",
       " 'Or': 1372,\n",
       " '@ShipsXAnchors': 9744,\n",
       " 'hackers': 18639,\n",
       " 'I': 13,\n",
       " 'facility': 7258,\n",
       " 'Choudary': 11810,\n",
       " 'scattered': 25084,\n",
       " 'actin': 16676,\n",
       " '-': 14,\n",
       " 'and': 15,\n",
       " 'Ghetto': 12904,\n",
       " 'http://t.co/8LkMWp9qzw': 19353,\n",
       " 'approval': 6879,\n",
       " 'Bounty': 4158,\n",
       " 'Billionaires': 11378,\n",
       " 'Rebahe': 15030,\n",
       " 'traffic': 1071,\n",
       " 'Latest': 318,\n",
       " 'conversation': 7086,\n",
       " 'EB': 3308,\n",
       " 'seeks': 25129,\n",
       " '@CortezEra': 8993,\n",
       " 'Port': 4487,\n",
       " 'WW1': 2924,\n",
       " 'York': 1047,\n",
       " '@firstpostin': 10276,\n",
       " 'http://t.co/tdeQwm8ZXn': 22443,\n",
       " '@KingMyth1999': 9390,\n",
       " 'freespeech': 7317,\n",
       " 'Korea': 4380,\n",
       " 'able': 1751,\n",
       " 'is': 19,\n",
       " 'San\\x89Ûªa': 15397,\n",
       " 'sunburned': 25570,\n",
       " 'http://t.co/ndCy8Q7R6I': 22045,\n",
       " 'Iran': 398,\n",
       " '35': 2662,\n",
       " 'China': 378,\n",
       " 'for': 20,\n",
       " 'okwx': 2589,\n",
       " '@organicallyrude': 10564,\n",
       " 'urgent': 26010,\n",
       " 'character': 1971,\n",
       " '32': 4032,\n",
       " 'Produc': 14840,\n",
       " 'mayhem': 3068,\n",
       " 'Eligible': 12409,\n",
       " 'Forecast': 2388,\n",
       " 'bts': 6987,\n",
       " 'used': 718,\n",
       " 'Kowing': 6125,\n",
       " 'airport': 4679,\n",
       " 'League': 13765,\n",
       " 'it': 24,\n",
       " 'FB100': 12551,\n",
       " 'on': 21,\n",
       " 'drug': 4829,\n",
       " 'cup': 4790,\n",
       " 'Diesel': 12206,\n",
       " 'misty': 23984,\n",
       " 'http://t.co/jW3hN9ewFT': 21778,\n",
       " 'died': 736,\n",
       " 'Make': 914,\n",
       " 'Browser': 1850,\n",
       " 'bombing': 197,\n",
       " 'Grill': 2398,\n",
       " \"'s\": 22,\n",
       " 'Reno': 4511,\n",
       " 'Express': 1702,\n",
       " 'Holy': 3366,\n",
       " '@djryanwolf': 10225,\n",
       " 'OVER': 14443,\n",
       " 'Sought': 15611,\n",
       " 'scary': 2612,\n",
       " 'bioterror': 513,\n",
       " '@author_mike': 10058,\n",
       " 'dreaming': 7184,\n",
       " 'The': 25,\n",
       " 'screaming': 745,\n",
       " '@sayed_ridha': 10636,\n",
       " 'trend.\\x89Û\\x9d': 25873,\n",
       " 'http://t.co/YmP0gInwza': 21059,\n",
       " 'Awesome': 5564,\n",
       " 'drowned': 542,\n",
       " 'samples': 25055,\n",
       " 'evolved': 18174,\n",
       " \"I'M\": 1893,\n",
       " 'having': 642,\n",
       " '@KristyLeeMusic': 9397,\n",
       " 'Mxaaaa': 14227,\n",
       " 'age': 4677,\n",
       " 'you': 23,\n",
       " 'gotten': 2549,\n",
       " 'land': 448,\n",
       " 'Former': 1704,\n",
       " '@sriramk': 10677,\n",
       " 'combust': 17485,\n",
       " 'Face': 1352,\n",
       " 'Hannah': 13091,\n",
       " 'http://t.co/hPd3SNM6oy': 21629,\n",
       " 'Ai': 4103,\n",
       " '@RyleeDowns02': 9703,\n",
       " 'shut': 2043,\n",
       " 'ZENIT': 16603,\n",
       " '@DianneG': 9067,\n",
       " 'http://t.co/y9WvqKGbBI': 22734,\n",
       " 'fact': 1992,\n",
       " 'recount': 1235,\n",
       " 'HAHAH': 13006,\n",
       " 'out': 55,\n",
       " 'lion': 3803,\n",
       " 'captured': 4744,\n",
       " 'Hostages': 1712,\n",
       " '@RejectdCartoons': 9670,\n",
       " 'NoChillLukeHammings': 14368,\n",
       " 'bout': 1963,\n",
       " 'http://t.co/LMWKjsYCgj': 20216,\n",
       " 'they': 73,\n",
       " 'http://t.co/mUAnfWcRW9': 21975,\n",
       " 'States': 1931,\n",
       " ' ': 26,\n",
       " 'caring': 17290,\n",
       " 'rubble': 1658,\n",
       " '@ScreamQueens': 5426,\n",
       " 'widout': 26204,\n",
       " 'scared': 1068,\n",
       " 'Prompting': 14849,\n",
       " 'CAFire': 11554,\n",
       " '\\n': 27,\n",
       " 'http://t.co/ZDTz3RbS6w': 21089,\n",
       " 'bets': 6944,\n",
       " 'battleship': 6933,\n",
       " 'http://t.co/h99bHB29xt': 21604,\n",
       " 'restive': 7791,\n",
       " 'rape': 3894,\n",
       " 'my': 29,\n",
       " 'Rule': 6508,\n",
       " '.@wwp': 8209,\n",
       " 'electrical': 3704,\n",
       " 'FlavorChargedTea': 12704,\n",
       " 'mosque': 605,\n",
       " 'ESH': 12346,\n",
       " 'shit': 258,\n",
       " 'CDC': 3268,\n",
       " 'certain': 2964,\n",
       " 'Doritos': 12258,\n",
       " 'with': 30,\n",
       " 'http://t.co/gVAipmLSl0': 21556,\n",
       " 'hopped': 18782,\n",
       " 'YELLOW': 16563,\n",
       " 'WE': 2921,\n",
       " 'after': 63,\n",
       " 'Battlefield': 2345,\n",
       " 'MFi': 13925,\n",
       " 'Derivatives': 12182,\n",
       " 'at': 31,\n",
       " 'Falcon': 3335,\n",
       " 'http://t.co/iaDlSlqdpd': 21714,\n",
       " 'do': 50,\n",
       " 'Freaking': 12759,\n",
       " 'YouGov': 16593,\n",
       " 'impulse': 7473,\n",
       " 'hoops': 18781,\n",
       " 'OKs': 6322,\n",
       " 'ALEC': 10851,\n",
       " 'Vermont': 4630,\n",
       " 'Handling': 13088,\n",
       " 'Accident': 661,\n",
       " 'serve': 7835,\n",
       " 'Move': 4433,\n",
       " 'EITHER': 12320,\n",
       " 'http://t.co/VCq2icptKI': 20871,\n",
       " '9': 377,\n",
       " 'hot': 244,\n",
       " 'designs': 7144,\n",
       " 'Fake': 5913,\n",
       " '@salon': 10627,\n",
       " 'http://t.co/n3yJb8TcPm': 22010,\n",
       " 'Kisii': 2415,\n",
       " '@halljh1720': 10317,\n",
       " 'http://t.co/mFJxh4p51U': 21957,\n",
       " 'smiles': 7875,\n",
       " 'large': 7539,\n",
       " 'by': 32,\n",
       " 'recovered': 24822,\n",
       " 'http://t.co/sbfGLQjZfs': 22369,\n",
       " ';': 33,\n",
       " 'taxes': 25662,\n",
       " 'http://t.co/bXGNQ57xvb': 21229,\n",
       " 'reward': 3914,\n",
       " 'deaths': 420,\n",
       " 'UN': 3543,\n",
       " 'flat': 3729,\n",
       " 'crossed': 2984,\n",
       " \"n't\": 34,\n",
       " '@Ebolatrends': 9104,\n",
       " 'which': 330,\n",
       " 'JaN': 13452,\n",
       " 'collectibles': 17472,\n",
       " 'OffensiveåÊContent': 4460,\n",
       " 'broke': 1617,\n",
       " 'accepts': 16658,\n",
       " 'asking': 2947,\n",
       " 'Try': 16093,\n",
       " 'Foothill': 12730,\n",
       " 'CREE': 2353,\n",
       " 'Motordom': 14195,\n",
       " 'lauren': 23652,\n",
       " 'lad': 23622,\n",
       " 'SIDED': 6520,\n",
       " '_': 35,\n",
       " 'Safsufa': 15368,\n",
       " 'Iranians': 6071,\n",
       " 'Berlatsky': 11353,\n",
       " 'Wait': 2925,\n",
       " 'Issue': 2777,\n",
       " 'Targeting': 4602,\n",
       " 'crematoria': 1207,\n",
       " 'blamed': 2955,\n",
       " 'cause': 302,\n",
       " 'Silver': 1273,\n",
       " 'driving': 1130,\n",
       " 'rise': 715,\n",
       " '@tomarse99': 10744,\n",
       " 'Funko': 12796,\n",
       " 'indie': 7477,\n",
       " 'lol': 280,\n",
       " 'sitting\\x89Û': 5163,\n",
       " 'Cover': 3289,\n",
       " 'Rep': 6469,\n",
       " '@almusafirah': 10033,\n",
       " 'flame': 18342,\n",
       " 'up': 49,\n",
       " 'desires': 1499,\n",
       " 'leave': 649,\n",
       " '2500': 8445,\n",
       " 'see': 137,\n",
       " '320': 2065,\n",
       " 'humidity': 7451,\n",
       " 'SB': 4525,\n",
       " 'be': 37,\n",
       " 'http://t.co/0C1y8g7E9p': 18813,\n",
       " 'occupants': 5028,\n",
       " 'runs': 3125,\n",
       " 'have': 39,\n",
       " 'arm': 4692,\n",
       " 'times': 796,\n",
       " 'Akwa': 10992,\n",
       " 'programme': 7726,\n",
       " 'Plane': 1271,\n",
       " 'from': 40,\n",
       " '@iateyourfood': 10348,\n",
       " 'http://t.co/BJ4hAAVAYE': 19553,\n",
       " 'Refugees': 1921,\n",
       " 'tastes': 5210,\n",
       " 'Sophie': 3507,\n",
       " '@antpips67': 10039,\n",
       " 'HOW': 3353,\n",
       " '@LondonFire': 5411,\n",
       " 'spill': 430,\n",
       " 'respect': 3909,\n",
       " 'mad': 2576,\n",
       " 'groom': 7350,\n",
       " '@UnivSFoundation': 9896,\n",
       " '@biggangVH1': 10084,\n",
       " 'will': 61,\n",
       " 'Pea': 14670,\n",
       " 'http://t.co/tGcR5voFJ3': 22416,\n",
       " 'evacuated': 465,\n",
       " 'TESTIFY': 15816,\n",
       " 'friend': 938,\n",
       " 'Bernard': 11355,\n",
       " 'as': 51,\n",
       " 'Personal': 6378,\n",
       " 'How': 156,\n",
       " 'SCREAMED': 1923,\n",
       " 'are': 41,\n",
       " 'ADIDAS': 10831,\n",
       " 'Windsor': 16491,\n",
       " '10:30': 3198,\n",
       " 'http://t.co/QbMcSJaVt0': 20576,\n",
       " 'Denver': 1459,\n",
       " 'keeps': 2240,\n",
       " 'whirlwind': 752,\n",
       " '@southridgelife': 10671,\n",
       " 'mix': 5002,\n",
       " 'this': 42,\n",
       " 'http://t.co/pw3tZU0tay': 22197,\n",
       " 'happen': 1512,\n",
       " 'quoteoftheday': 24738,\n",
       " 'arcade': 16837,\n",
       " 'SRK': 15315,\n",
       " 'example': 3714,\n",
       " 'Somebody': 6597,\n",
       " 'taking': 1070,\n",
       " 'Gagnon': 12859,\n",
       " 'postponed': 24568,\n",
       " 'Chester': 11790,\n",
       " 'traditionalist': 25846,\n",
       " 'SCSeEstaPreparando': 15219,\n",
       " 'prison': 5077,\n",
       " 'StrategicPatience': 2886,\n",
       " '41': 8533,\n",
       " 'Remix': 6465,\n",
       " '@CochiseCollege': 8982,\n",
       " 'crazy': 1291,\n",
       " 'Take': 766,\n",
       " 'managed': 7577,\n",
       " 'SP': 15301,\n",
       " 'http://t.co/KXrEHVt6hL': 20162,\n",
       " 'like': 43,\n",
       " 'McFadden': 14081,\n",
       " 'http://t.co/euDwNFyUeM': 21455,\n",
       " 'Outdoor': 6344,\n",
       " 'anything': 595,\n",
       " 'tons': 3972,\n",
       " 'Swag': 15777,\n",
       " 'session': 25160,\n",
       " 'disrespect': 17913,\n",
       " 'Earth': 1699,\n",
       " 'streets': 2047,\n",
       " 'h': 7359,\n",
       " 'so': 58,\n",
       " '(': 44,\n",
       " '@dannyonpc': 4071,\n",
       " 'http://t.co/VCkIT6EDEv': 20870,\n",
       " 'opening': 1791,\n",
       " 'NBC10': 14241,\n",
       " '52k': 8571,\n",
       " 'http://t.co/NXtWXJCAVh': 20374,\n",
       " 'flag': 4874,\n",
       " 'Reunion': 505,\n",
       " 'Levy': 13793,\n",
       " 'archetype': 16838,\n",
       " 'Elliott': 5866,\n",
       " 'Around': 4117,\n",
       " 'Island': 536,\n",
       " 'commuters': 17503,\n",
       " '@TonyAbbottMHR': 9871,\n",
       " 'Ebola': 1253,\n",
       " 'exited': 7247,\n",
       " 'Yourself': 2495,\n",
       " 'https://t.co/AIM5CYHL0y': 22916,\n",
       " 'balding': 16978,\n",
       " 'That': 229,\n",
       " 'watchout': 26139,\n",
       " 'KOTAWeather': 6104,\n",
       " '@dviyer': 10238,\n",
       " 'EBOLA': 5839,\n",
       " 'entire': 1054,\n",
       " 'A': 45,\n",
       " 'darsena': 17709,\n",
       " 'alert': 16741,\n",
       " 'Tacos': 15889,\n",
       " 'guys': 740,\n",
       " 'FIRE': 2741,\n",
       " 'http://t.co/9cgbJwmhII': 19433,\n",
       " 'Bus': 1852,\n",
       " 'Sir': 6583,\n",
       " 'amp': 47,\n",
       " 'sunset': 3950,\n",
       " 'HARM': 1889,\n",
       " 'ChawalChorbjp': 11784,\n",
       " 'NORTHERN': 14268,\n",
       " 'Blizzard': 2089,\n",
       " 'profit': 5079,\n",
       " 'http://t.co/jAxHzjCCd4': 21751,\n",
       " 'behavior': 17036,\n",
       " 'me': 48,\n",
       " 'loudest': 23773,\n",
       " 'pussy': 2030,\n",
       " 'Tied': 15995,\n",
       " 'just': 52,\n",
       " 'inundated': 425,\n",
       " 'seen': 842,\n",
       " '7/10': 8627,\n",
       " 'Caesar': 11679,\n",
       " 'Interstate': 13396,\n",
       " 'Risk': 3478,\n",
       " '@SonyProUSA': 9765,\n",
       " 'contemplating': 7079,\n",
       " 'Writer': 6811,\n",
       " 'your': 53,\n",
       " 'those': 329,\n",
       " 'tonight': 454,\n",
       " 'risk': 1528,\n",
       " 'Breeder': 11473,\n",
       " 'Off': 1370,\n",
       " 'Gods': 4304,\n",
       " 'not': 56,\n",
       " 'member': 3821,\n",
       " '@ThreatConnect': 9865,\n",
       " 'Saving': 15410,\n",
       " 'has': 57,\n",
       " 'randomthought': 24763,\n",
       " 'via': 62,\n",
       " 'band': 6922,\n",
       " 'white': 1004,\n",
       " 'curiosity': 7111,\n",
       " 'calgary': 4740,\n",
       " '@VictoriaGittins': 9914,\n",
       " 'Listen': 1100,\n",
       " 'injury': 424,\n",
       " 'disappearing': 17878,\n",
       " 'OtleyHour': 14519,\n",
       " 'Cyclone': 963,\n",
       " 'http://t.co/zCKXtFc9PT': 22800,\n",
       " 'helping': 1777,\n",
       " 'an': 64,\n",
       " 'stars': 3144,\n",
       " 'Foster': 4284,\n",
       " 'If': 125,\n",
       " 'ultimate': 8018,\n",
       " 'florida': 18358,\n",
       " 'entrepreneur': 7219,\n",
       " 'Remembering': 2860,\n",
       " 'Daily': 1250,\n",
       " 'about': 66,\n",
       " 'Nevada': 14332,\n",
       " 'stunned': 7929,\n",
       " 'truckload': 25896,\n",
       " 'ball': 984,\n",
       " '1000': 4017,\n",
       " 'i': 67,\n",
       " '@DiscoveryCntr': 9069,\n",
       " 'smeared': 25300,\n",
       " 'bloody': 461,\n",
       " '@bonhomme37': 10099,\n",
       " 'Diebold': 12203,\n",
       " 'http://t.co/ddhWoRI5w1': 21372,\n",
       " 'http://t.co/GETBjip5Rh': 19863,\n",
       " 'abuses': 16654,\n",
       " 'BULLETIN': 5585,\n",
       " '@evebrigid': 10269,\n",
       " 'no': 68,\n",
       " 'Arabian': 3238,\n",
       " 'insults': 23418,\n",
       " 'Flag': 907,\n",
       " 'drive': 1767,\n",
       " 'Chrysler': 11813,\n",
       " '@Earths_Voice': 9102,\n",
       " 'capoeira': 17272,\n",
       " 'Peel': 14678,\n",
       " 'County': 397,\n",
       " 'Now': 205,\n",
       " 'order': 789,\n",
       " 'Environmental': 12456,\n",
       " 'ripple': 24967,\n",
       " '@emmerdale': 2072,\n",
       " '1665': 8349,\n",
       " 'get': 69,\n",
       " 'Element': 5862,\n",
       " '@adultblackmale': 10016,\n",
       " 'tokyo': 25801,\n",
       " 'when': 70,\n",
       " 'reason': 1145,\n",
       " '114': 8305,\n",
       " 'corners': 17591,\n",
       " 'banned': 867,\n",
       " 'Them': 1482,\n",
       " 'CANT': 3267,\n",
       " 'joined\\x89Û': 23521,\n",
       " 'appreciate': 4691,\n",
       " 'maj': 23818,\n",
       " 'been': 72,\n",
       " '@deadlydemi': 10207,\n",
       " 'wounded': 532,\n",
       " 'activates': 3588,\n",
       " 'lie': 2248,\n",
       " 'https://t.co/ttq9IlHp8W': 23202,\n",
       " 'miss': 1317,\n",
       " 'Download': 5825,\n",
       " 'Blast': 1848,\n",
       " 'Hoof': 13208,\n",
       " 'islam': 1136,\n",
       " 'CoD': 11855,\n",
       " 'fire': 74,\n",
       " 'Aberdeen': 10909,\n",
       " 'arrested': 1489,\n",
       " 'Abortion': 10915,\n",
       " 'Tae': 15891,\n",
       " '@ictyosaur': 10350,\n",
       " 'superbug': 25576,\n",
       " 'http://t.co/7nAgdSAdWP': 19314,\n",
       " 'ensuing': 18127,\n",
       " 'Statement': 3516,\n",
       " 'KS94': 6106,\n",
       " '@eileenmfl': 10250,\n",
       " '@hanna_brooksie': 10318,\n",
       " 'yeat': 26300,\n",
       " 'cars': 1050,\n",
       " '@theblaze': 10715,\n",
       " 'tweeting': 25915,\n",
       " 'Edward': 5857,\n",
       " 'State': 538,\n",
       " 'USAR2015': 16155,\n",
       " 'captives': 17274,\n",
       " '@Casper_rmg': 5400,\n",
       " 'liked': 289,\n",
       " 'snotgreen': 25328,\n",
       " 'SOUDELOR': 6526,\n",
       " 'Natural': 2147,\n",
       " 'ending': 3709,\n",
       " 'terrorists': 2632,\n",
       " 'Given': 5980,\n",
       " 'he': 75,\n",
       " 'http://t.co/iD4QGqDnJQ': 21680,\n",
       " 'we': 76,\n",
       " 'Baby': 903,\n",
       " 'fundamentals': 18459,\n",
       " 'swallowed': 7947,\n",
       " 'single': 2044,\n",
       " 'bored': 3627,\n",
       " 'victim': 1438,\n",
       " '2': 77,\n",
       " 'signs': 717,\n",
       " 'indy': 23364,\n",
       " 'Gunshot': 5996,\n",
       " 'ways': 3179,\n",
       " 'WOOOOOOO': 16367,\n",
       " 'Legionnaires': 209,\n",
       " '*': 78,\n",
       " \"'\\x89Û\": 8128,\n",
       " '100s': 8283,\n",
       " '@Jake_ADavis': 9305,\n",
       " 'change': 462,\n",
       " 'queer': 24731,\n",
       " 'spontaneously': 7901,\n",
       " 'Push': 14882,\n",
       " '@NDzedze': 9538,\n",
       " 'Thomas': 2173,\n",
       " 'David': 2103,\n",
       " 'hey': 2001,\n",
       " 'Georgina': 12900,\n",
       " 'prebreak': 496,\n",
       " '@channelstv': 10128,\n",
       " 'alternate': 16762,\n",
       " 'Stretcher': 1383,\n",
       " 'http://t.co/4yu5Sy1Cui': 19136,\n",
       " 'goku': 7336,\n",
       " 'CLICK': 5664,\n",
       " 'BP': 3251,\n",
       " 'importance': 23322,\n",
       " 'YALL': 6817,\n",
       " 'Airplane': 2333,\n",
       " 'Fatality': 1256,\n",
       " 'Statistically': 15681,\n",
       " 'nflexpertpicks': 24153,\n",
       " 'over': 79,\n",
       " 'Blight': 2088,\n",
       " 'lifetime': 7554,\n",
       " 'danger': 675,\n",
       " 'Di': 3302,\n",
       " 'http://t.co/CpQguFZB28': 19649,\n",
       " 'people': 80,\n",
       " 'Loosers': 13851,\n",
       " 'https://t.co/T07qxP5cBE': 23024,\n",
       " 'http://t.co/rrZbZGO48N': 22320,\n",
       " 'http://t.co/5XRC0a76vD': 19166,\n",
       " 'http://t.co/2JxkmkpalP': 18964,\n",
       " 'Poss': 6404,\n",
       " 'Skies': 6586,\n",
       " 'flying': 3733,\n",
       " 'Before': 2346,\n",
       " 'rediscovered': 24830,\n",
       " 'In': 81,\n",
       " 'headquarters': 18704,\n",
       " 'amid': 770,\n",
       " 'into': 82,\n",
       " 'GoKitGo': 12932,\n",
       " 'Has': 1098,\n",
       " 'http://t.co/DaqszZuBUb': 19684,\n",
       " 'went': 434,\n",
       " 'Ashes2Ashes': 11118,\n",
       " 'plane': 945,\n",
       " 'http://t.co/vMWTOUyOHm': 22553,\n",
       " 'San': 1595,\n",
       " 'Centers': 5696,\n",
       " 'short': 2286,\n",
       " 'Palermo': 6360,\n",
       " 'IS': 362,\n",
       " 'trust': 1821,\n",
       " '@realdonaldtrump': 10596,\n",
       " 'Lady': 2419,\n",
       " '@YahooSchwab': 9959,\n",
       " 'Uganda': 3544,\n",
       " 'Vintage': 3555,\n",
       " 'http://t.co/KmTwA3n1Gf': 20179,\n",
       " 'rioters': 7800,\n",
       " 'https://t.co/EfKCoegJck': 22940,\n",
       " '\\n\\n': 83,\n",
       " 'Deal': 1860,\n",
       " 'handbags': 7363,\n",
       " 'suicide': 147,\n",
       " '@BaileySMSteach': 8860,\n",
       " 'http://t.co/NniXodHIGc': 20390,\n",
       " 'unavoidable': 5241,\n",
       " 'http://t.co/xQrLEWiA4x': 22675,\n",
       " 'Health': 1023,\n",
       " '@AIIAmericanGirI': 8757,\n",
       " 'Burton': 11530,\n",
       " '0': 1005,\n",
       " 'one': 84,\n",
       " 'http://t.co/8kscqKfKkF': 19377,\n",
       " 'gays': 7332,\n",
       " 'Abha': 10911,\n",
       " 'dropped': 1985,\n",
       " 'SEVERE': 2164,\n",
       " 'can': 85,\n",
       " 'veterans': 2645,\n",
       " 'Details': 3301,\n",
       " 'devastation': 464,\n",
       " 'BOWL': 11233,\n",
       " 'if': 86,\n",
       " 'hungrier': 23252,\n",
       " '|': 87,\n",
       " 'collided': 349,\n",
       " 'esp': 4852,\n",
       " 'Mayhem': 1263,\n",
       " 'It': 88,\n",
       " 'Urgent': 6739,\n",
       " 'large\\x89Û': 23639,\n",
       " 'http://t.co/mkqSVp8E0': 21988,\n",
       " 'by\\x89Û': 2519,\n",
       " '@Jason_Floyd': 9312,\n",
       " 'SA15': 15203,\n",
       " 'https://t.co/Ysxun5vCeh': 23066,\n",
       " 'Barack': 5592,\n",
       " 'now': 89,\n",
       " 'light': 1221,\n",
       " 'remorseless': 24873,\n",
       " 'mm': 23989,\n",
       " 'movie': 351,\n",
       " 'what': 90,\n",
       " '@FedEx': 9144,\n",
       " 'Riot': 728,\n",
       " 'One': 335,\n",
       " 'who': 92,\n",
       " 'Redwing': 15046,\n",
       " 'Scary': 15417,\n",
       " 'ya': 3191,\n",
       " 'Want': 2490,\n",
       " 'Effort': 5858,\n",
       " 'lt;p&gt;An': 23788,\n",
       " 'http://t.co/UoJy4E2Sv4': 20843,\n",
       " 'UTICA': 16167,\n",
       " 'COLLISION': 2699,\n",
       " 'thundering': 25760,\n",
       " 'Artwork': 11111,\n",
       " 'money': 835,\n",
       " 'more': 91,\n",
       " 'Tent': 2901,\n",
       " '513': 8567,\n",
       " 'endangered': 7210,\n",
       " 'opened': 3079,\n",
       " 'Laboratory': 13715,\n",
       " 'stations': 25449,\n",
       " 'inundation': 2565,\n",
       " 'protests': 7730,\n",
       " 'years': 204,\n",
       " '@Bonn1eGreer': 8903,\n",
       " 'Hieroglyphics': 2765,\n",
       " 'there': 93,\n",
       " 'sprains': 25416,\n",
       " 'Offer': 14463,\n",
       " 'SoundCloud': 2882,\n",
       " 'attack': 146,\n",
       " '@burberryant': 10113,\n",
       " 'wiWNpFXA': 26202,\n",
       " 'providers': 24669,\n",
       " 'spot': 1810,\n",
       " 'than': 94,\n",
       " 'crossfit': 17653,\n",
       " 'France': 1021,\n",
       " 'fav': 3015,\n",
       " 'traditional': 3169,\n",
       " 'Emergency': 152,\n",
       " '3': 109,\n",
       " 'would': 95,\n",
       " 'declares': 3685,\n",
       " 'YAY': 16559,\n",
       " 'putting': 5089,\n",
       " 'Mountain': 2435,\n",
       " '@MarianKeyes': 9474,\n",
       " 'beam': 17018,\n",
       " 'protection': 7729,\n",
       " 'COMPLIANT': 3270,\n",
       " 'http://t.co/xwxBYHTuzC': 22712,\n",
       " '[': 96,\n",
       " 'goes': 492,\n",
       " 'Free': 1022,\n",
       " 'Tips': 3533,\n",
       " 'Dubbo': 12294,\n",
       " '@MeekMill': 5413,\n",
       " \"'re\": 97,\n",
       " 'Road': 920,\n",
       " 'Of': 241,\n",
       " 'desolate': 874,\n",
       " 'Nah': 14293,\n",
       " 'Working': 3576,\n",
       " 'wheelers': 26185,\n",
       " 'LN;COL;YELLOWSTONE': 13693,\n",
       " ']': 98,\n",
       " 'loud': 311,\n",
       " '8/6/15': 5374,\n",
       " 'DOOMSDAY': 12078,\n",
       " '..': 99,\n",
       " 'hope': 325,\n",
       " 'Beluga': 11341,\n",
       " 'Calling': 3273,\n",
       " 'Zouma': 3584,\n",
       " 'RCHS': 14928,\n",
       " 'artists': 16864,\n",
       " 'beforeitsnews': 3614,\n",
       " '90225': 8685,\n",
       " 'EM': 12324,\n",
       " 'NATIONAL': 14237,\n",
       " 'Oracle': 14497,\n",
       " 'Rory': 6496,\n",
       " 'California': 101,\n",
       " 'IMPACT': 6053,\n",
       " '3rd': 3208,\n",
       " 'DEVEREAUX': 12053,\n",
       " 'stripe': 25506,\n",
       " 'You': 102,\n",
       " 'Merle.--': 14108,\n",
       " 'games': 1404,\n",
       " 'http://t.co/ZdiEodWbog': 21108,\n",
       " 'show': 609,\n",
       " 'Combust': 11880,\n",
       " 'place': 650,\n",
       " 'rapper': 7754,\n",
       " 'tcot': 3154,\n",
       " 'overblown': 24324,\n",
       " 'http://t.co/bGAJ2oAX1p': 21209,\n",
       " 'dispatch': 17909,\n",
       " 'here': 184,\n",
       " 'HELLO': 6004,\n",
       " 'reef': 24834,\n",
       " 'his': 103,\n",
       " 'Title': 6697,\n",
       " 'KasabWe': 13590,\n",
       " '@Crystal_Blaz': 9010,\n",
       " 'http://t.co/KPQk0C4G0': 20158,\n",
       " 'throwing': 3968,\n",
       " 'aching': 16669,\n",
       " 'well': 375,\n",
       " 'Immigrant': 13337,\n",
       " 'Twilight': 16119,\n",
       " 'We': 104,\n",
       " 'http://t.co/sPuHuvgAsy': 22357,\n",
       " 'airhead': 16725,\n",
       " 'Going': 1887,\n",
       " 'Death': 854,\n",
       " ...}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = vocab.get_stoi()\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import FastText\n",
    "fast_vectors = FastText(language='simple') #small for easy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26442, 300])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_embedding = fast_vectors.get_vecs_by_tokens(vocab.get_itos()).to(device)\n",
    "fast_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_embedding = fast_vectors.get_vecs_by_tokens(vocab.get_itos()).to(device)\n",
    "\n",
    "#since the fasttext  has 300 embedding\n",
    "assert fast_embedding.shape == (len(vocab), 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline  = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1 #turn {1, 2, 3, 4} to {0, 1, 2, 3} for pytorch training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 185, 10, 683, 2229]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"I love to play football\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline('1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To fit the padnas dataframe to DataLoader first we must wrap it as DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PD_DATASET(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataframe.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \n",
    "valid = \n",
    "test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data   import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "pad_idx = vocab['<pad>'] #++<----making sure our embedding layer ignores pad\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "    #criterion expects float labels\n",
    "    return torch.tensor(label_list, dtype=torch.int64), pad_sequence(text_list, padding_value=pad_idx, batch_first=True)\n",
    "## copy the collate_batch function from Professor's code. But it will not work right away\n",
    "##  mind how the dataset that we use is structured (hint: columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[1;32m----> 3\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train, batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      4\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, collate_fn\u001b[39m=\u001b[39mcollate_batch)\n\u001b[0;32m      5\u001b[0m valid_loader \u001b[39m=\u001b[39m DataLoader(valid, batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      6\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, collate_fn\u001b[39m=\u001b[39mcollate_batch)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(valid, batch_size=batch_size,\n",
    "                              shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First lets try CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## Get the Professor's code from  the lab to build the CNN model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    pass #replace this line with the respected code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class simpleRNN(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.RNN(emb_dim, hid_dim, batch_first=True)\n",
    "        self.fc  = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #text = [batch size, seq len]\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [batch size, seq len, embed dim]\n",
    "        output, hn = self.rnn(embedded)  #if no h0, all zeroes\n",
    "        \n",
    "        #output = [batch size, seq len, hidden dim]\n",
    "        #hidden = [1, batch size, hidden dim]\n",
    "        \n",
    "        assert torch.equal(output[:,-1,:], hn.squeeze(0))\n",
    "        return self.fc(hn.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, output_dim, dropout, n_filters, filter_sizes):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[0], emb_dim))\n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[1], emb_dim))\n",
    "        self.conv_2 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[2], emb_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, seq len]\n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, seq len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)  #<----make text as 1 dimensional data for Conv2d\n",
    "        #embedded = [batch size, 1, seq len, emb dim]\n",
    "        \n",
    "        #squeeze 3 because maxpool1d expect only three dimen tensor\n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3)) #conved_0 = [batch_size, n_filters,  seq len - filter_sizes[n] + 1]\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3)) #conved_1 = [batch_size, n_filters,  seq len - filter_sizes[n] + 1]\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3)) #conved_2 = [batch_size, n_filters,  seq len - filter_sizes[n] + 1]\n",
    "        #conved_n = [batch size, n_filters, seq len - filter_sizes[n] + 1]\n",
    "        \n",
    "        #conv0_embedded_squeezed.shape[2] because we want to take max out from the whole weighted sum array\n",
    "        #we squeeze 2 for linear layer\n",
    "        \n",
    "        #F.max_pool1d(input, kernel_size) => [batch_size, n_filters, 1]\n",
    "        # After squeeze(2) => [batch_size, n_filters]\n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = len(vocab)\n",
    "emb_dim    =  #how many embedding does the fasttext have \n",
    "output_dim =  #how many classes do we have\n",
    "dropout    = 0.5\n",
    "n_filters  = 100 \n",
    "filter_sizes = [3, 4, 5]\n",
    "\n",
    "model = CNN(input_dim, emb_dim, output_dim, dropout, n_filters, filter_sizes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "seq_len    = 50\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explicitly initialize weights for better learning\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, (nn.Conv2d, nn.Conv2d)):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.kaiming_normal_(param) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39m#training hyperparameters\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[0;32m      7\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss() \u001b[39m#combine softmax with cross entropy\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr=1e-3\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss() #combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    \n",
    "    predicted = torch.max(preds.data, 1)[1]\n",
    "    batch_corr = (predicted == y).sum()\n",
    "    acc = batch_corr / len(y)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, loader_length):\n",
    "    #write the code to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    #write the code to evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs      = 5\n",
    "\n",
    "save_path = f'./models/{model.__class__.__name__}.pt'\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        #write the code that starts the training, store the training and valid losses and accuracy\n",
    "    #also print the time it took to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot the training loss and the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Try the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = PD_DATASET(train_data)\n",
    "valid = PD_DATASET(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    pass #replace this line with the real code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = len(vocab)\n",
    "emb_dim    = #same as above\n",
    "hidden_dim = #how many hidden dims do you want?\n",
    "output_dim = #same as above\n",
    "dropout    = 0.5\n",
    "num_layers = 2\n",
    "bidirectional = True \n",
    "\n",
    "lstm_model = LSTM(input_dim, emb_dim, hidden_dim, output_dim, num_layers, bidirectional, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr=1e-3\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, loader_length):\n",
    "    #write the code to train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    #write the code to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs   = 5\n",
    "\n",
    "save_path = f'./models/lstm_{model.__class__.__name__}.pt'\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #write the code that starts the training, store the training and valid losses and accuracy\n",
    "    #also print the time it took to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot the losses and accuracy over all epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- Compare the two models on their time and accuracy. Which one do you think did well for the disaster classification task.\n",
    "- How do you think we get better results in this dataset for classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a5e0dd1bb1c7782ce55b8cc0782cb511f0ece1dcdb1ee0c0eca7637fe7f72b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
